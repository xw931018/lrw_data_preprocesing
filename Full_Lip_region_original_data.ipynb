{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export PATH='$PATH:/home/monga/.local/lib/python3.8/site-packages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import util\n",
    "from psfdataset import PSFDataset, transforms\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import util_lip_data as util_lip\n",
    "import custom_transforms as ctransform\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 THOUGHT\n",
      "2 INVOLVED\n",
      "3 DIFFERENT\n",
      "4 MAYBE\n",
      "5 REPORT\n",
      "6 VICTIMS\n",
      "7 GETTING\n",
      "8 UNION\n",
      "9 MEDIA\n",
      "10 VIOLENCE\n",
      "-------------------------------\n",
      "dict_keys(['THOUGHT', 'INVOLVED', 'DIFFERENT', 'MAYBE', 'REPORT', 'VICTIMS', 'GETTING', 'UNION', 'MEDIA', 'VIOLENCE'])\n",
      "dict_keys(['val', 'test', 'train'])\n",
      "1000\n",
      "(29, 20, 2)\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "script to compute the number\n",
    "of jsons created for each\n",
    "word. The output is a .csv\n",
    "file where for each word the\n",
    "number of jsons corresponding\n",
    "to train, val, and test subsets\n",
    "is mentioned\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_rect_and_landmarks(rect, landmarks):\n",
    "    # converts and returns the face rectangle and landmarks\n",
    "    # in formats appropriate for the display function\n",
    "\n",
    "    x = rect[\"left\"]\n",
    "    y = rect[\"top\"]\n",
    "    w = rect[\"width\"]\n",
    "    h = rect[\"height\"]\n",
    "\n",
    "    if landmarks is not None:\n",
    "        temp_agg = list()\n",
    "        for i in range(len(landmarks)):\n",
    "            temp = list()\n",
    "            temp.append(landmarks[\"point-\" + str(i+1)][\"x\"])\n",
    "            temp.append(landmarks[\"point-\" + str(i+1)][\"y\"])\n",
    "            temp_agg.append(temp)\n",
    "        return (x, y, w, h), np.asarray(temp_agg)\n",
    "    else:\n",
    "        return (x, y, w, h), np.empty((0, 0))\n",
    "\n",
    "\n",
    "def choose_the_largest_face(faces_list):\n",
    "    if len(faces_list) == 1: \n",
    "        return faces_list[0]\n",
    "    \n",
    "    area_max = 0\n",
    "    area_max_id = 0\n",
    "    for i,face in enumerate(faces_list):\n",
    "        (face_rect,landmarks) = face\n",
    "        area = face_rect[2] * face_rect[3] # area = width * height\n",
    "        if area > area_max:\n",
    "            area_max = area\n",
    "            area_max_id = i\n",
    "    return faces_list[area_max_id]\n",
    "\n",
    "\n",
    "def load_one_json_file(filename, isDebug=False):\n",
    "    # load the metadata and facial landmarks\n",
    "\n",
    "    face_rect_list = []\n",
    "    landmarks_list = []\n",
    "    with open(filename) as f:\n",
    "        video_data_dict = json.load(f)\n",
    "        # extract duration\n",
    "        if video_data_dict[\"metaData\"] is not None:\n",
    "            duration = float(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", video_data_dict[\"metaData\"][\"Duration\"])[0])\n",
    "            if isDebug:\n",
    "                print(\"duration metadata: %.3f\" % duration)\n",
    "\n",
    "        # extract frame information aggregated for all frames\n",
    "        agg_frame_data = video_data_dict[\"aggFrameInfo\"]  # list of frame-wise visual data\n",
    "\n",
    "        for frame_data in agg_frame_data:\n",
    "            n_faces = frame_data[\"numFaces\"]\n",
    "            if isDebug:\n",
    "                print(\"frame index: %d number of faces: %d\" % (frame_data[\"frameIndex\"], n_faces))\n",
    "            \n",
    "            if frame_data[\"facialAttributes\"] is not None:# if so, the n_faces should > 0 \n",
    "                faces_list = []\n",
    "                for attr in frame_data[\"facialAttributes\"]:\n",
    "                    face_idx = attr[\"faceIndex\"]\n",
    "                    face_rect, landmarks = get_rect_and_landmarks(attr[\"faceRectangle\"],\n",
    "                                                                  attr[\"faceLandmarks\"])\n",
    "                    faces_list.append((face_rect, landmarks))\n",
    "\n",
    "                face_rect_chosen, landmarks_chosen = choose_the_largest_face(faces_list)    \n",
    "                face_rect_list.append(face_rect_chosen)\n",
    "                landmarks_list.append(landmarks_chosen)\n",
    "    \n",
    "    face_rect_array = np.array(face_rect_list)\n",
    "    landmarks_array = np.array(landmarks_list)\n",
    "    return face_rect_array, landmarks_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i_data = \"/cache/lrw/lipread_landmarks/dlib68_2d_sparse_json/lipread_mp4\"\n",
    "# or i_data = \"/cache/lrw/lipread_landmarks/dlib68_2d_sparse_json_defects_not_one_face/lipread_mp4\"\n",
    "selected_n_classes = 10 # the max is 500\n",
    "\n",
    "cnt = 0\n",
    "data = dict()\n",
    "\n",
    "for word in os.listdir(i_data):\n",
    "    if not word.startswith('.'):\n",
    "        cnt += 1\n",
    "        if cnt > selected_n_classes:\n",
    "            break\n",
    "        print(cnt,word)\n",
    "        splits = dict() # 'train' 'val' and 'test' sets\n",
    "        # print(\"analysing data for the word: '%s'\" % word)\n",
    "        p = os.path.join(i_data, word)\n",
    "        \n",
    "        for sub_dir in os.listdir(p):\n",
    "            if not sub_dir.startswith('.'):\n",
    "                # print(sub_dir)\n",
    "                p_sub = os.path.join(p, sub_dir)\n",
    "                for _, _, files in os.walk(p_sub):\n",
    "                    samples_list = []\n",
    "                    for filename in files:\n",
    "                        if filename.endswith('.json'):\n",
    "                            face_rect_array, landmarks_array = load_one_json_file(os.path.join(p_sub, filename))\n",
    "                            lip_region = []\n",
    "                            for j in range(len(landmarks_array)):\n",
    "                                lip_region.append(landmarks_array[j][48:68])\n",
    "                            samples_list.append(np.array(lip_region))\n",
    "                    splits[sub_dir] = samples_list\n",
    "        data[word] = splits\n",
    "\n",
    "print('-------------------------------')\n",
    "print(data.keys()) # names of all the 'selected_n_classes' classes  \n",
    "print(data['THOUGHT'].keys()) # print the names of the 3 splits for the first class 'THOUGHT'\n",
    "print(len(data['THOUGHT']['train'])) # print the number of train samples of the first class\n",
    "print(data['THOUGHT']['train'][0].shape) # print the shape (29 frames, 68 landmarks, 2 coordinates) of the first training sample of the first class    \n",
    "print('-------------------------------')                     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Defining a LabelEncoder to transform text class to numberic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder= LabelEncoder()\n",
    "categories = list(data.keys())\n",
    "encoder.fit(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Defining my custom Data loader from above 'data'. We only need to properly define iterators for train/test/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_iterator(data, key = 'train', refLength = 29):\n",
    "    iter_list = []\n",
    "    x = 0\n",
    "    for word, keypointsOneWord in data.items():\n",
    "        \n",
    "\n",
    "        keypointsList = keypointsOneWord[key]\n",
    "        num_of_samples = len(keypointsList)\n",
    "        \n",
    "        ## There are some sample whose length is smaller than 29. We need to either delete it, \n",
    "        ## or extend it to 29 length for now. But this can be resolved if signature transform is introduced\n",
    "        for i in range(len(keypointsList)):\n",
    "             singleSample = keypointsList[i]\n",
    "             if len(singleSample) < refLength:\n",
    "                 singleSample = np.array(list(singleSample) + [singleSample[-1]] * (refLength - len(singleSample)))\n",
    "                 keypointsList[i] = singleSample\n",
    "        iter_list = iter_list + list(zip(keypointsList, np.array(list(encoder.transform([word])) * num_of_samples)))\n",
    "    return iter(iter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = generate_iterator(data, key = 'train')\n",
    "iter_test = generate_iterator(data, key = 'test')\n",
    "iter_val = generate_iterator(data, key = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiter_test = [x for x in iter_test]\n",
    "iiter_train = [x for x in iter_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Let's adapt the PSFDataset from human body movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([\n",
    "    #transforms.spatial.Crop(),\n",
    "#     transforms.spatial.Normalize(),\n",
    "#     transforms.SpatioTemporalPath(),\n",
    "#     transforms.temporal.MultiDelayedTransformation(2),\n",
    "    transforms.temporal.DyadicPathSignatures(dyadic_levels=2,\n",
    "                                             signature_level=4)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first steps, no transforms are introduced yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create new dictionaries identical to 'data' that contain the normalized landmarks without aumenting \n",
    "#the training set\n",
    "\n",
    "    \n",
    "d_normalize = {} # normalized data set\n",
    "for i in data: \n",
    "    d_normalize[i] = dict((k,ctransform.normalize_based_on_first_frame(v)) for k, v in data[i].items())\n",
    "    \n",
    "d_rotate = {}    # rotated data set \n",
    "for i in data: \n",
    "    d_rotate[i] = dict((k,ctransform.rotate(v)) for k, v in data[i].items())\n",
    "        \n",
    "    \n",
    "d_normalize_rotate= {} # normalized and rotated data set\n",
    "for i in d_normalize:\n",
    "    d_normalize_rotate[i] = dict((k,ctransform.rotate(v)) for k, v in d_normalize[i].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new dictionary identical to 'data' that contains the normalized landmarks augmenting \n",
    "#the training set\n",
    "\n",
    "aug_data = ctransform.flip_train_augmentation(data)\n",
    "\n",
    "d_normalize_a = {} #normalized data set\n",
    "for i in data: \n",
    "    d_normalize_a[i] = dict((k,ctransform.normalize_based_on_first_frame(v)) for k, v in aug_data[i].items())\n",
    "    \n",
    "d_rotate_a = {}    #rotated data set \n",
    "for i in data: \n",
    "    d_rotate_a[i] = dict((k,ctransform.rotate(v)) for k, v in aug_data[i].items())\n",
    "        \n",
    "    \n",
    "d_normalize_rotate_a= {} ## normalized and rotated data set\n",
    "for i in d_normalize_a:\n",
    "    d_normalize_rotate_a[i] = dict((k,ctransform.rotate(v)) for k, v in d_normalize_a[i].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [02:11, 151.56it/s]\n",
      "500it [00:03, 154.11it/s]\n",
      "500it [00:03, 151.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainingset elements: 20000\n",
      "Number of testset elements 500\n",
      "Dimension of feature vector: 6293\n",
      "Initial accuracy: 0.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ce5211f92341bc802897fdfd4e7e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=20.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e203f973948a4ebd86da46a4abfe8f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 0', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 53647.36871088239 \ttest_loss: 36212.44252317939 \tAccuracy: 0.408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f167050d3e84f569fe4073e5003658a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 1', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 34991.81579210107 \ttest_loss: 24924.255764445552 \tAccuracy: 0.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b54186f33934f17baafddb721fad4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 2', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 21855.80334065536 \ttest_loss: 15596.386247132574 \tAccuracy: 0.454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10b08db192947969e296895f82e7d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 3', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 14885.964397440466 \ttest_loss: 8766.01392920388 \tAccuracy: 0.496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f633c18140bf406989fcdc3aec7154b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 4', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11728.425209570833 \ttest_loss: 8864.395754741978 \tAccuracy: 0.466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedb20068af74c7985d539a3dfcc1c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 5', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11350.189323721219 \ttest_loss: 11214.168874323806 \tAccuracy: 0.428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4084ab58e9d14155bb72bc284d758194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 6', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11135.88865549389 \ttest_loss: 12020.811146712571 \tAccuracy: 0.352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d881d3937ff044fc901edd923dfd3bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 7', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11530.443732201711 \ttest_loss: 11377.233505551174 \tAccuracy: 0.422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b5c4bdf6c54abdba35fa7c5204e842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 8', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11679.771469897838 \ttest_loss: 11520.160327625188 \tAccuracy: 0.446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f32537ff1644c59bbc9c8230ac94bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 9', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11590.278490348035 \ttest_loss: 9732.633176885363 \tAccuracy: 0.486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff3a2f8b44042c4a2a4221991f90a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 10', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11687.246252144721 \ttest_loss: 13629.210942960624 \tAccuracy: 0.414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370f90406fc3479e8e4acbc7a9cd1884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 11', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11906.627124561148 \ttest_loss: 13419.658351049158 \tAccuracy: 0.438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf73a17fffdf462e86ec8fa3dbf6e7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 12', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11893.275740444768 \ttest_loss: 14587.244169866088 \tAccuracy: 0.404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd09611206cb4a128ff91f2e2aed1c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 13', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 12062.643031014735 \ttest_loss: 12046.041562648848 \tAccuracy: 0.472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebca0e75370c4d18a94a5bd4e49577b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 14', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 12308.739347956132 \ttest_loss: 11364.021273294524 \tAccuracy: 0.454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10933f06580843a885fc4229c37921b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 15', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 11906.688496896382 \ttest_loss: 11024.988776945793 \tAccuracy: 0.514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fca495cc5ef40bc8a363ee8529b6f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 16', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 12322.115554176538 \ttest_loss: 10640.580543040134 \tAccuracy: 0.474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9044c18ad1fa4d36bf303fe1e3841bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 17', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 12225.136683959658 \ttest_loss: 14111.640002011278 \tAccuracy: 0.404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8b7215b36a44aab1ef27e8a808839c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epoch 18', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, outputs = ctransform.trainModelWithSpecificDataDict(dataDict = data, transforms = tr, EPOCHS = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
